{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://zijing.us/wordpress/index.php/2017/08/06/298-binary-tree-longest-consecutive-sequence/': 20, 'http://zijing.us/wordpress/index.php/tag/zend-engine-analysis/': 16, 'http://zijing.us/wordpress/index.php/2017/08/06/199-binary-tree-right-side-view/': 20, 'http://zijing.us/wordpress/': 6}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from InvertedIndex import InvertedIndex\n",
    "from Tries import Tries\n",
    "\n",
    "MINIMUM_CHR = 2\n",
    "MAP_PATH = \"file_link_map.json\"\n",
    "class SearchEngine(object):\n",
    "    inverted_index = InvertedIndex()\n",
    "\n",
    "    def buildTries(self):\n",
    "        f = open(MAP_PATH, \"r\") \n",
    "        file_link_map = json.loads(f.readlines()[0]) \n",
    "\n",
    "        # filter stopword and punctuation\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stop_words.update(string.punctuation)\n",
    "\n",
    "        for filename in file_link_map:\n",
    "            f = open(filename)\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "            [script.extract() for script in soup.findAll('script')]\n",
    "            [style.extract() for style in soup.findAll('style')]\n",
    "#             print file_link_map[filename]\n",
    "            words = word_tokenize(soup.get_text())\n",
    "            # remove the words containing punctuation\n",
    "            words = [i for i in words if all(j not in string.punctuation for j in i)]\n",
    "            \n",
    "            for word in words:\n",
    "                if word.lower() not in stop_words and len(word) > MINIMUM_CHR and word.isdigit()==False:\n",
    "                        # build compressed trie tree\n",
    "                        try:\n",
    "                            # remove the words whcih can't encode to ascII\n",
    "                            word = word.lower().strip().encode('ascII')\n",
    "                        except:\n",
    "#                             print word\n",
    "                            a = 1\n",
    "                        else:\n",
    "                            self.inverted_index.put(word, file_link_map[filename])\n",
    "#                             print word.lower().strip()\n",
    "        f.close()\n",
    "        \n",
    "    def search(self, key):\n",
    "        if self.inverted_index.get(key) == None:\n",
    "            return {}\n",
    "        else:\n",
    "            return self.inverted_index.get(key)\n",
    "    \n",
    "    def getRecomendKey(self, string):\n",
    "        return self.inverted_index.getRecommendKey(string) \n",
    "        \n",
    "        \n",
    "# se = SearchEngine()\n",
    "# se.buildTries()\n",
    "# keywords = [\"algorithm\", \"leetcode\", \"bit\"]\n",
    "# keylist = []\n",
    "# odict = {}\n",
    "# for key in keywords:\n",
    "#     result = se.search(key)\n",
    "#     if result:\n",
    "#         result.pop('key', None)\n",
    "#         keylist.append(result.keys())\n",
    "#         for r in result:\n",
    "#             if odict.has_key(r):\n",
    "#                 odict[r] = odict[r] + result[r]\n",
    "#             else:\n",
    "#                 odict[r] = result[r]\n",
    "#     else:\n",
    "#         keylist.append(result.keys())\n",
    "        \n",
    "# intersetion = None\n",
    "# for kl in keylist:\n",
    "#     if intersetion == None:\n",
    "#         intersetion = set(kl)\n",
    "#     else:\n",
    "#         intersetion = set(intersetion) & set(kl)\n",
    "        \n",
    "# output = {}\n",
    "\n",
    "# for sub_intersetion in intersetion:\n",
    "#     sub = sub_intersetion.encode(\"utf-8\")\n",
    "#     output[sub] = odict[sub]\n",
    "\n",
    "# print output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
